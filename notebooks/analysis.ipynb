{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c293e96d-e022-4ee4-9af0-29d9a9013aa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-24T19:33:43.074707Z",
     "iopub.status.busy": "2023-10-24T19:33:43.074344Z",
     "iopub.status.idle": "2023-10-24T19:33:44.772426Z",
     "shell.execute_reply": "2023-10-24T19:33:44.771834Z",
     "shell.execute_reply.started": "2023-10-24T19:33:43.074609Z"
    },
    "tags": []
   },
   "source": [
    "# 1. Initial setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6078fb50-35f1-4cda-b748-4688c804c7e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Required packages and databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf7ef68-4b56-484d-bcd1-dbed66c0f8ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "Our analysis requires several software packages that can be installed via `conda` using the provided environment file (`environment.yml`). Additionally, we require [USEARCH](https://www.drive5.com/usearch/manual/install.html) and `SQLite3`. The latter can be installed using `sudo apt-get install sqlite3`\n",
    "\n",
    "### Downloading UHGG\n",
    "Our analysis also requires the UHGG and UHGP-90 databases from [Almedia et al., (2020)](https://www.nature.com/articles/s41587-020-0603-3). Specifically:\n",
    "\n",
    "1. [UHGG catalogue](https://ftp.ebi.ac.uk/pub/databases/metagenomics/mgnify_genomes/human-gut/v1.0/uhgg_catalogue/) saved in a folder called `data/uhgg/uhgg_catalogue`;\n",
    "2. [UHGP-90](https://ftp.ebi.ac.uk/pub/databases/metagenomics/mgnify_genomes/human-gut/v1.0/uhgp_catalogue/uhgp-90.tar.gz) saved in `data/uhgg/uhgp-90`;\n",
    "3. [UHGG Kraken DB](https://ftp.ebi.ac.uk/pub/databases/metagenomics/mgnify_genomes/human-gut/v1.0/uhgg_kraken2-db/) saved in `data/uhgg/uhgg_kraken2-db`; and\n",
    "4. [All UHGG genomes](https://ftp.ebi.ac.uk/pub/databases/metagenomics/mgnify_genomes/human-gut/v1.0/all_genomes/) saved in `data/uhgg/all_genomes`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451157af-5fe5-4b5b-bf5d-07ef1e73d5ca",
   "metadata": {},
   "source": [
    "### AlphaFold (AFDB) mappings\n",
    "\n",
    "To map the UHGP-90 database onto AlphaFold along with AFDB clusters (see [Barrio-Hernandez et al., (2023)](https://nature.com/articles/s41586-023-06510-w)), we need the following saved in a directory called `data/uhgg/foldseek`:\n",
    "1. [AFDB catalogue](https://github.com/google-deepmind/alphafold/blob/main/afdb/README.md) saved as `afdb.faa`; and\n",
    "2. [AFDB clusters](https://afdb-cluster.steineggerlab.workers.dev/5-allmembers-repId-entryId-cluFlag-taxId.tsv.gz) from [Barrio-Hernandez et al., (2023)](https://nature.com/articles/s41586-023-06510-w) saved as `afdb.cluster.tsv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea4f0e2-753e-4e99-b676-bad8650d9178",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd87d93-4a26-404c-91c1-77c657d7e4d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Merging genome annotations\n",
    "UHGG provides GFF, InterProScan, and KEGG annotations for genomes. For convenience, we merge these into a single annotation file using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c5d319-cda7-43e2-898a-cdbd15b4e293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath('../../mgxevo/src/'))\n",
    "import mgxevo as mg\n",
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "os.makedirs('write', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68fb73a-4320-4a33-9960-1bc1735ea3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$mg.tl.uhgg.script_path\"\n",
    "\n",
    "# get a list of MGYGs from UHGG \n",
    "cut -f 18 data/uhgg/genomes-nr_metadata.tsv | tail -n +2 | sort -u > data/uhgg/genomes-nr.mgyg_ids.txt\n",
    "\n",
    "# iterate script over these MGYGs\n",
    "uhgg_catalogue=\"./data/uhgg/uhgg_catalogue/\"\n",
    "script_path=\"$1\"\n",
    "\n",
    "annotate_gene() {\n",
    "    x=\"$1\"\n",
    "    ifn=\"${uhgg_catalogue}$(echo ${x} | cut -c 1-13)/${x}/genome/${x}.gff\"\n",
    "    \n",
    "    # Convert gff to gtf\n",
    "    agat_convert_sp_gff2gtf.pl --gff $ifn --out ${ifn/.gff/.gtf} > /dev/null 2>&1\n",
    "    \n",
    "    # merge annotation\n",
    "    Rscript ${script_path}/4.gene_annotations_mgyg.r --MGYG_id $x --uhgg_catalogue $uhgg_catalogue\n",
    "}\n",
    "\n",
    "export -f annotate_gene\n",
    "export uhgg_catalogue\n",
    "export script_path\n",
    "\n",
    "cat data/uhgg/genomes-nr.mgyg_ids.txt | parallel --progress -j360 annotate_gene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c816d54e-41be-485a-99f4-d8f577dfdf63",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Mapping UHGP locus IDs onto UHGP-90\n",
    "\n",
    "Mapping a UHGP locus ID onto its UHGP-90 protein ID is computationally expensive. One way to address this is to use `SQLite3` to build an SQL database:\n",
    "```\n",
    "sqlite3 uhgg.sqlite\n",
    "sqlite> create table map(seed,gene);\n",
    "sqlite> .mode tabs\n",
    "sqlite> .import data/uhgg/uhgp-90/uhgp-90.tsv map\n",
    "sqlite> .schema map\n",
    "```\n",
    "\n",
    "This allows us to efficiently map the gene loci found in UHGG's presence-absence matrices (`*.genes_presence-absence_locus.csv`) onto their respective UHGP-90 protein IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f6ad2-9031-4bce-b5ab-e0a16cb0e3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$mg.tl.uhgg.script_path\"\n",
    "\n",
    "cat data/uhgg/genomes-nr.mgyg_ids.txt | parallel --progress -j360 Rscript $1/3.map2uhgp90.r {} ./data/uhgg/\n",
    "\n",
    "# map UHGP90 IDs to KEGG\n",
    "Rscript $1/5.uhgp90-kegg.r --uhgp90_dir \"./data/uhgg/uhgp90/\" --output \"./data/uhgg/uhgp90/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a48dd4-360a-4534-94b9-c67ef2c7855b",
   "metadata": {},
   "source": [
    "#### Mapping UHGP-90 onto AlphaFold (AFDB) and AFDB clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b6ea48-356a-43d7-a2f5-4b0245588821",
   "metadata": {},
   "source": [
    "To map UHGP-90 IDs onto AlphaFold proteins we can use the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21bb199-7f58-4761-9efd-f3ddc19dd872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$mg.tl.uhgg.script_path\"\n",
    "\n",
    "python $1/6.uhgp90-afdb.py \"./data/uhgg/foldseek/afdb.faa\" \"./data/uhgg/uhgp90/uhgp-90_hq.faa\" > ./write/uhgp2afdb.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914a572f-f2f3-471a-a6a1-b577b1f883b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T19:17:29.311289Z",
     "iopub.status.busy": "2024-04-02T19:17:29.310932Z",
     "iopub.status.idle": "2024-04-02T19:17:29.326110Z",
     "shell.execute_reply": "2024-04-02T19:17:29.325242Z",
     "shell.execute_reply.started": "2024-04-02T19:17:29.311187Z"
    },
    "tags": []
   },
   "source": [
    "The resulting mapping of UHGP-90 onto AlphaFold (`/write/uhgp2afdb.tsv`) can then be merged with the AFDB clusters (`afdb.cluster.tsv`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6cb078-333a-4f5d-bcd9-4409b7379670",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Processing metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d60ede-a6aa-48f3-afa4-60fbdf884a7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T02:10:50.938571Z",
     "iopub.status.busy": "2023-10-25T02:10:50.938279Z",
     "iopub.status.idle": "2023-10-25T02:10:50.948207Z",
     "shell.execute_reply": "2023-10-25T02:10:50.947327Z",
     "shell.execute_reply.started": "2023-10-25T02:10:50.938542Z"
    }
   },
   "source": [
    "Our analysis requires Table S1 (saved as `dx.csv` when importing `mgxevo`) from the manuscript along with an extra column called `file` for where the corresponding FASTA is saved. **Note:** each sample should only have _one_ entry in the `file` column. Paired reads can be denoted using a wildcard (_e.g._, `example_R*.fastq.gz` for `example_R1.fastq.gz` and `example_R2.fastq.gz`). The following commands process this information into files that will be used for read mapping: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb4f464-ec41-435f-8586-249753bfcb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# assumes reads are saved in data/reads/\n",
    "mgx = glob.glob('data/reads/*')\n",
    "mgx = [f.replace('_R1', '_R*') for f in mgx]\n",
    "mgx = [f.replace('_R2', '_R*') for f in mgx]\n",
    "mgx = sorted(list(set(mgx)))\n",
    "\n",
    "# generate list of samples\n",
    "samples = [f.split('/')[-1].replace('.trim.fastq.gz', '').replace('_R*', '') for f in mgx]\n",
    "with open('data/samples.txt', 'w') as f:\n",
    "    f.write('\\n'.join(samples))\n",
    "\n",
    "# align metadata to sample list\n",
    "meta = mg.data.metadata.query('`Sample ID` in @samples').sort_values('Sample ID').reset_index(drop=True)\n",
    "meta.to_csv('data/metadata.tsv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80ffac5-8f80-48f5-a52c-7cc9ed36bd40",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Mapping reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aeacd04-c258-4b8c-ab7b-c050427c08c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T05:59:50.032983Z",
     "iopub.status.busy": "2023-10-25T05:59:50.032706Z",
     "iopub.status.idle": "2023-10-25T05:59:50.038428Z",
     "shell.execute_reply": "2023-10-25T05:59:50.037805Z",
     "shell.execute_reply.started": "2023-10-25T05:59:50.032953Z"
    },
    "tags": []
   },
   "source": [
    "## Building a non-redundant set of reference marker gene sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc856793-d644-4d33-a9bc-6474b132a94c",
   "metadata": {},
   "source": [
    "To infer our strain genotypes, we use the following marker genes: _dnaG_, _rpoB_, and _gyrB_. To extract these marker genes from all representative genomes in UHGG we use the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb6af66-d1d5-4401-9141-f72879484c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath('../../mgxevo/src/'))\n",
    "import mgxevo as mg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce059204-a8b1-41a7-8459-050750f32ce9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$mg.tl.uhgg.script_path\"\n",
    "\n",
    "# get sequences\n",
    "genes=(\"dnaG\" \"gyrB\" \"rpoB\")\n",
    "for gene in ${genes[@]}; do\n",
    "    python $1/1.get_fasta.py --gene $gene --multi --mgyg ./data/uhgg/genomes-nr.mgyg_ids.txt --uhgg ./data/uhgg --out ./data/uhgg/marker_gene/${gene}.fst\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c976719b-ccaa-46d7-be87-e7d9a7962b9b",
   "metadata": {},
   "source": [
    "To cluster these sequences into non-redundant sets at 90% identity, we use USEARCH. Please note that USEARCH _may_ give different results depending on the how it is compiled and the machine architecture. For more information, please refer to the [USEARCH website](https://www.drive5.com/usearch/manual/reproduce.html). For reproducibility, we have provided the clustering results used in our analyses (_e.g._, see `assets/dnaG.fst` and `assets/dnaG.uc`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad42b4e-a5bb-4aa3-8372-6679052904df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$mg.tl.uhgg.script_path\"\n",
    "\n",
    "genes=(\"dnaG\" \"gyrB\" \"rpoB\")\n",
    "base_dir=\"./data/uhgg/marker_gene\"\n",
    "\n",
    "# run USEARCH\n",
    "for gene in ${genes[@]}; do\n",
    "    usearch11.0.667_i86linux32 -cluster_fast ${base_dir}/${gene}.fst -id 0.9 -sort length -centroids ${base_dir}/${gene}-nr.fst -uc ${base_dir}/${gene}.uc\n",
    "    rm ${base_dir}/${gene}-nr.fst.tmp\n",
    "done\n",
    "\n",
    "# concat into a single fasta\n",
    "cat ${base_dir}/{dnaG,gyrB,rpoB}-nr.fst > ${base_dir}/all-nr.fasta\n",
    "\n",
    "# generate an intermediary \"gene file\" for read mapping\n",
    "python $1/2.make_gene_file.py ${base_dir}/all-nr.fasta > ${base_dir}/all-nr.gene.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb9108a-9d08-40d9-9135-c4b42a878334",
   "metadata": {},
   "source": [
    "## Mapping reads against reference marker genes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62346513-330b-46dd-aac1-4fdc18eef9d9",
   "metadata": {},
   "source": [
    "To generate gene alignments, we use `bowtie2` and filter the resulting alignments (see **Methods**). The resulting alignment is saved in a \"pickled\" `numpy` array of dimensions _(M, L, 5)_, where:\n",
    "\n",
    "```\n",
    "M = number of samples\n",
    "L = number of alignment positions (alignment length)\n",
    "5 = nucleotides (A,C,G,T,N)\n",
    "```\n",
    "More specifically, each entry $(i, j, k)$ represents how often you observe nucleotide $k$ at position $j$ in sample $i$ of your alignment. Note that this step is slow. For convenience, we provide some examples of pickle outputs in the folder `assets/pickles`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f41484-2cbf-4804-a0c9-650ce012fe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$mg.tl.map.script_path\"\n",
    "\n",
    "# build bowtie2 database\n",
    "bowtie2-build ./data/uhgg/marker_gene/all-nr.fasta data/all-nr > /dev/null 2>&1\n",
    "\n",
    "# run bowtie and filter results\n",
    "# assumes FASTQs are in a folder called reads\n",
    "python $1/1.map_reads.py \\\n",
    "    --index ./data/all-nr \\\n",
    "    --fastq_dir ./data/reads \\\n",
    "    --outdir ./write/ \\\n",
    "    --sample_file ./data/samples.txt \\\n",
    "    --gene_file ./data/uhgg/marker_gene/all-nr.gene.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab6e564-128d-4eb0-982c-6ce2ce2e6af8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Phylogenies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ed9b40-a4ef-4beb-86a8-8da0b7caa843",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Marker gene panel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1ec66e-460a-4fc8-9314-d8a3236faa64",
   "metadata": {},
   "source": [
    "To build our marker gene panel, we first generate a gene counts matrix. Next, we parse our `USEARCH` clustering results to map alleles onto their non-redundant representative sequences. Together, this allows us to select the marker genes alleles that the most correlated across our metagenomes (see **Methods**). Since we add a small amount of random noise, the resulting panel may change each time you run this script.  For reproducibility, we have provided the panel results used in our analyses (`assets/ids.multigene.txt'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbab354-6df0-487c-9cc4-0b1be0a88ade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath('../../mgxevo/src/'))\n",
    "import mgxevo as mg\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# make a folder called abundance\n",
    "os.makedirs('abundance', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcb0f07-0dfa-4f8a-9235-33ebce8427c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$mg.tl.marker.script_path\" \"$mg.data.metadata_path\"\n",
    "\n",
    "# build abundance/counts matrix\n",
    "python $1/1.get_bowtie_abundances.py \\\n",
    "    --species_path ./write/kpileup/ \\\n",
    "    --samples_path ./data/samples.txt \\\n",
    "    --output_path ./abundance\n",
    "\n",
    "# parse USEARCH results to map allels onto rep seqs\n",
    "python $1/2.map_ids.py \\\n",
    "    --uclust_path ./data/uhgg/marker_gene/ \\\n",
    "    --genes dnaG gyrB rpoB \\\n",
    "    --output_file ./write/gene_ids.txt\n",
    "\n",
    "# use the above data to select marker gene alleles that best supported \n",
    "Rscript $1/3.select_ids.r \\\n",
    "    --abundance_file ./write/abundance/bowtie_abundances.csv \\\n",
    "    --metadata $2 \\\n",
    "    --map_ids ./write/gene_ids.txt \\\n",
    "    --genes dnaG gyrB rpoB \\\n",
    "    --uhgg_catalogue ./data/uhgg/uhgg_catalogue \\\n",
    "    --uhgg_metadata ./data/uhgg/genomes-nr_metadata.tsv \\\n",
    "    --output_dir ./write/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1bd2c4-32b1-4e6d-9804-9dc09db99b1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Maximum likelihood phylogenetic inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dd012b-6abb-4de6-8b07-7123d18f875e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Single-gene phylogenies\n",
    "To build single-gene phylogenies, we run `IQTree2` on consensus sequences from our alignment (again, see **Methods**). The resulting phylogenies are stored in the `write` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60930d4d-182d-44fc-aa91-cba88f934930",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load marker panel and extract all markers\n",
    "ids = pd.read_table('write/ids.multigene.txt')\n",
    "markers = sorted(list(set(ids[['dnaG', 'gyrB', 'rpoB']].values.flatten())))\n",
    "\n",
    "# write this list of markers to file\n",
    "with open('write/marker_gene_ids.txt', 'w') as f:\n",
    "    f.write('\\n'.join(markers))\n",
    "    \n",
    "iterate over these markers to build phylogenies\n",
    "for marker in tqdm(markers):\n",
    "    mg.tl.tree.snp_util.get_phylogeny_from_pickle(\n",
    "        pickle_file=f'./write/kpileup/{marker}.aln.pickle',\n",
    "        gene_file='./data/uhgg/marker_gene/all-nr.gene.txt',\n",
    "        dx_file='./data/metadata.tsv',\n",
    "        threads=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1629c0bf-e04a-4b8e-a3bc-2c4db2e28d43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T23:02:56.156616Z",
     "iopub.status.busy": "2023-10-25T23:02:56.156328Z",
     "iopub.status.idle": "2023-10-25T23:02:56.164965Z",
     "shell.execute_reply": "2023-10-25T23:02:56.164151Z",
     "shell.execute_reply.started": "2023-10-25T23:02:56.156583Z"
    }
   },
   "source": [
    "### Multi-gene phylogenies\n",
    "\n",
    "To build multi-gene phylogenies, we use a partition model in `IQTree2` along with the resulting output from our single-single gene phylogenies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a14726-0b6e-43ea-bd9b-500a95dee5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define panel\n",
    "marker_genes = ['dnaG', 'gyrB', 'rpoB']\n",
    "\n",
    "# save the genomes we want to build phylogenies for\n",
    "genomes = sorted(ids['genome'].unique())\n",
    "with open('write/genomes.txt', 'w') as f:\n",
    "    f.write('\\n'.join(genomes))\n",
    "\n",
    "# generate symlinks \n",
    "mg.ut.create_symlinks(base_dir=os.getcwd(), \n",
    "                      source_files='./write/*fas.gb',\n",
    "                      destination_dir='./data')\n",
    "\n",
    "# concat FASTAs for downstream analyses\n",
    "for _, row in tqdm(multigene_table.iterrows(), total=multigene_table.shape[0]):\n",
    "    gene_ids = row[marker_genes].values\n",
    "    mg.tl.tree.snp_util.process_fna_gb(\n",
    "        fasta_path='./data/',\n",
    "        gene_ids=gene_ids,\n",
    "        name=row['genome'],\n",
    "    )\n",
    "\n",
    "# define a wrapper function that we can parallelise\n",
    "def process_genome(row):\n",
    "    gene_ids = row[1][marker_genes].values\n",
    "    mg.tl.tree.snp_util.multigene_phylo(\n",
    "        fasta_path='./data/',\n",
    "        gene_ids=gene_ids,\n",
    "        fasta_ext = 'fas.gb',\n",
    "        name=row[1]['genome'],\n",
    "        output='./write/multigene_phylo',\n",
    "        threads=1,\n",
    "    )\n",
    "    return\n",
    "\n",
    "# execute jobs in parallel\n",
    "with ThreadPoolExecutor(max_workers=360) as executor:\n",
    "    list(tqdm(executor.map(process_genome, ids.iterrows()), total=ids.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7910cf8e-2c98-40b9-884b-2eb0a51cb486",
   "metadata": {},
   "source": [
    "Note that you can also provide a `seed` for reproducibility. For example, to generate the _B. intestinalis_ phylogeny from **Figure 2A** you can use `seed = 676418`, along with the example FASTAs provided in the `assets` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adcb15b-703e-475a-a312-1952c467389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load panel for GUT_GENOME001255\n",
    "gene_ids = ids.loc[ids.genome=='GUT_GENOME001255'][marker_genes].values\n",
    "\n",
    "# generate tree \n",
    "# note that the *.processed.fas.gb were generated from the single gene phylogeny step\n",
    "mg.tl.tree.snp_util.multigene_phylo(\n",
    "    fasta_path='./assets/',\n",
    "    gene_ids=gene_ids,\n",
    "    name=row[1]['genome'],\n",
    "    output='./write/multigene_phylo',\n",
    "    threads=1,\n",
    "    seed= 676418\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acc3d08-df69-4777-85c9-55b8a3398669",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T00:26:09.244050Z",
     "iopub.status.busy": "2023-10-26T00:26:09.243714Z",
     "iopub.status.idle": "2023-10-26T00:26:09.249936Z",
     "shell.execute_reply": "2023-10-26T00:26:09.249273Z",
     "shell.execute_reply.started": "2023-10-26T00:26:09.244015Z"
    },
    "tags": []
   },
   "source": [
    "## Integration of reference genomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817164a6-cda5-4bd4-81bb-3dd9e33cd75d",
   "metadata": {},
   "source": [
    "### Identifying sequences to be integrated into phylogenies\n",
    "To integrate reference genomes into our phylogenies, we first BLAST our template sequences (_i.e._, the sequences used to generate our phylogenies) against all marker genes from the entire UHGG catalog. The resulting BLAST hits are then filtered and processed. Specifically, we convert them to FASTA files where each file contains reference sequences to be integrated into their respective phylogenies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8088e41a-6ab0-4aca-88fb-630e00fa265c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write template sequences to file\n",
    "x = ids[marker_genes]\n",
    "x = x.melt(value_name='gene').dropna()['gene'].unique()\n",
    "f = mg.ut.seq_util.read_fst(\"./data/uhgg/marker_gene/all-nr.fasta\")\n",
    "mg.ut.seq_util.dict2fasta({k: f[k] for k in x}, './write/all.tree-seeds.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5998b7d7-a405-4c4d-bd4d-fc1db990adee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$mg.tl.marker.script_path\" \n",
    "\n",
    "# write marker genes from entire UHGG catalog to file\n",
    "python $1/4.merge_mgyg.py \\\n",
    "    --multigene_table ./write/ids.multigene.txt \\\n",
    "    --uhgg_dir ./data/uhgg/ \\\n",
    "    --genes dnaG gyrB rpoB \\\n",
    "    --output_file ./write/pangenome_markers.fasta\n",
    "\n",
    "# make BLAST database\n",
    "makeblastdb -in ./write/pangenome_markers.fasta -dbtype nucl > ./tmp/makeblastdb.log\n",
    "\n",
    "# run BLAST \n",
    "blastn -query ./write/all.tree-seeds.fasta \\\n",
    "    -db ./write/pangenome_markers.fasta \\\n",
    "    -outfmt 6 \\\n",
    "    -evalue 1e-5 \\\n",
    "    -max_target_seqs 100000000 \\\n",
    "    -num_threads 30 \\\n",
    "    -out ./write/tree-seeds.mgyg.b6 > ./tmp/blastn.log\n",
    "\n",
    "# filter blast results to keep only HQ matches (see methods)\n",
    "python $1/5.filter_blast.py \\\n",
    "    --fasta ./write/all.tree-seeds.fasta \\\n",
    "    --blast ./write/tree-seeds.mgyg.b6 \\\n",
    "    --filtered_blast ./write/tree-seeds.mgyg.filtered.b6\n",
    "\n",
    "# write to file (single gene phylogenies)\n",
    "mkdir -p ./write/marker_reference/\n",
    "python $1/6.blast2fna_single.py \\\n",
    "    --filtered_blast ./write/tree-seeds.mgyg.filtered.b6 \\\n",
    "    --multigene_table ./write/ids.multigene.txt \\\n",
    "    --pangenome_marker ./write/pangenome_markers.fasta \\\n",
    "    --genes dnaG gyrB rpoB \\\n",
    "    --output_dir ./write/marker_reference/\n",
    "\n",
    "# process results for multigene phyo (keep only marker gene hits from same genome)\n",
    "Rscript $1/7.proc_refmap.r \\\n",
    "    --multigene_table ./write/ids.multigene.txt \\\n",
    "    --blast_results ./write/tree-seeds.mgyg.filtered.b6 \\\n",
    "    --marker_mapping ./write/marker_reference/tree-seeds.mgyg.filtered.ref_map.txt \\\n",
    "    --output_dir ./write/marker_reference/\n",
    "\n",
    "# write and concat seqs to file (multigene phlyo)\n",
    "python $1/8.write_refs.py \\\n",
    "    --refmap_proc_file ./write/marker_reference/tree-seeds.mgyg.filtered.ref_map.proc.txt \\\n",
    "    --tree_seq_file ./write/pangenome_markers.fasta \\\n",
    "    --output_dir ./write/marker_reference/multigene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525b7804-0d25-4178-b0c5-fef453544de9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T15:06:21.523415Z",
     "iopub.status.busy": "2023-10-26T15:06:21.523119Z",
     "iopub.status.idle": "2023-10-26T15:06:21.531110Z",
     "shell.execute_reply": "2023-10-26T15:06:21.530287Z",
     "shell.execute_reply.started": "2023-10-26T15:06:21.523384Z"
    }
   },
   "source": [
    "### Integration of sequences into phylogenies\n",
    "\n",
    "Having identified which sequences to integrate into our phylogenies, we now use [`UShER`](https://usher-wiki.readthedocs.io) to integrate these sequences into our trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa2e4c8-9bc9-41f7-a101-c5c0c292a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$mg.tl.tree.script_path\"\n",
    "\n",
    "# single gene \n",
    "cat ./write/marker_gene_ids.txt | parallel --progress -j 60 \"python $1/add_seqs2tree.py \\\n",
    "    --tree ./write/{}.tree \\\n",
    "    --name {} \\\n",
    "    --fasta ./write/{}.fas.gb \\\n",
    "    --gtf ../data/uhgg/marker_gene/all-nr.gene.txt \\\n",
    "    --seq ./write/marker_reference/{}.ref.fna \\\n",
    "    --output ./write/{}.ref.tree\"\n",
    "\n",
    "# multigene \n",
    "cat ./write/genomes.txt | parallel --progress -j 350 \"python $1/add_seqs2tree.multi.py \\\n",
    "    --tree ./write/multigene_phylo/{}.tree \\\n",
    "    --name {} \\\n",
    "    --fasta ./data/{}.fas.conaln.gb \\\n",
    "    --seq ./write/marker_reference/multigene/{}.refseq.fna \\\n",
    "    --multigene_table ./write/ids.multigene.txt \\\n",
    "    --refseq ./data/uhgg/marker_gene/all-nr.fasta \\\n",
    "    --genes dnaG gyrB rpoB \\\n",
    "    --output ./write/multigene_phylo/{}.ref.tree\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0519b0-bf61-4ba1-aa8f-eb52d8fb2fe2",
   "metadata": {},
   "source": [
    "# 4. Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5fcc2a-0e88-41ae-bf30-28403b3015be",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Enrichment\n",
    "\n",
    "The following code blocks allow us to test for phylogenetic enrichment (while controlling for covariates such as batch, **Methods**), while also testing for differential abundance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e02a3b-a47d-46d8-a2cc-77aefdaa9a33",
   "metadata": {},
   "source": [
    "### Phylogenetic enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae6bfa1-5225-4f20-8bc3-730a99506ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath('../../mgxevo/src/'))\n",
    "import mgxevo as mg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26589f25-df4d-484c-b3f7-89707da61413",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$mg.tl.enrich.script_path\" \"$mg.data.metadata_path\"\n",
    "\n",
    "# enrichment for single gene\n",
    "cat write/marker_gene_ids.txt | parallel --progress -j 28 \"Rscript $1/phylo.r \\\n",
    "    --name {} \\\n",
    "    --tree_file ./write/{}.tree \\\n",
    "    --metadata $2 \\\n",
    "    --output_dir ./write/single\n",
    "\n",
    "# enrichment for multigene gene\n",
    "cat ./write/genomes.txt | parallel --progress -j 28 \"Rscript $1/phylo.r \\\n",
    "    --name {} \\\n",
    "    --tree_file ./write/multigene_phylo/{}.tree \\\n",
    "    --metadata $2 \\\n",
    "    --output_dir ./write/multigene_phylo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab705539-6a8f-4dc1-ab3d-e11578f49ddf",
   "metadata": {},
   "source": [
    "### Differential abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be9d986-f575-4141-8712-b039d4ff3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$mg.tl.enrich.script_path\" \"$mg.data.metadata_path\"\n",
    "\n",
    "Rscript $1/abund.r \\\n",
    "    --bowtie_aln ./abundance/bowtie_abundances.csv \\\n",
    "    --metadata $2 \\\n",
    "    --multigene_table ./write/ids.multigene.txt \\\n",
    "    --output_dir ./write/ \\\n",
    "    --genes dnaG gyrB rpoB \\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ec5448-2393-493b-8556-a1218fd40cc4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Strain abundance estimates\n",
    "\n",
    "To estimate the abundances of strains, we use [StrainFinder](https://github.com/cssmillie/StrainFinder). To begin we first create a new `conda` environment for StrainFinder. We then select strains (see **Methods**) and convert them into a `numpy` array that we can input into StrainFinder. Finally, we run StrainFinder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b74002b-9497-4226-81b5-35d5a3722455",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$mg.tl.strainfinder.script_path\" \"$mg.data.metadata_path\"\n",
    "\n",
    "# create conda environment\n",
    "conda env create -f $1/environment.yml\n",
    "conda activate strainfinder\n",
    "\n",
    "# select strains to analyse \n",
    "Rscript $1/1.select_strains.r \\\n",
    "    --multigene_table ./write/ids.multigene.txt \\\n",
    "    --tree_dir ./write/multigene_phylo/ \\\n",
    "    --phylo_enrichment_dir ./write/multigene_phylo \\\n",
    "    --output_dir ./write/\n",
    "\n",
    "# concat into numpy for StrainFinder \n",
    "mkdir -p ./write/multigene_np\n",
    "python $1/2.merge_np.py \\\n",
    "    --strains ./write/genomes.use.txt \\\n",
    "    --aln_pickle_dir ./write/kpileup/ \\\n",
    "    --multigene_table ./write/ids.multigene.txt \\\n",
    "    --genes dnaG gyrB rpoB \\\n",
    "    --output_dir ./write/multigene_np\n",
    "\n",
    "# actually run strainfinder\n",
    "mkdir -p ./write/strainfinder\n",
    "for genome in (cat ./write/genomes.use.txt); do\n",
    "    python $1/3.run_sf.py \\\n",
    "        --genome $genome \\\n",
    "        --aln ./write/multigene_np/$genome.multigene.aln.pickle \\\n",
    "        --tree ./write/multigene_phylo/$genome.tree \\\n",
    "        --samples ./data/samples.txt \\\n",
    "        --metadata $2 \\\n",
    "        --final_tips ./write/strainfinder.final_tips.txt \\\n",
    "        --output ./write/strainfinder/$genome.sf.txt\n",
    "        --use_phylo 1\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7a4ecb-f8a1-4ab7-8bad-5eb65c74cf7b",
   "metadata": {},
   "source": [
    "By default, this only estimates strain abundances for samples that are in the multigene phylogeny. To generate estimates for all samples in the alignment use `--use_phylo 0`. This might be useful when estimating strain abundances for longitudinal samples (see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4e8ca2-81f7-458c-8a8b-a32e6c28862f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Summarize results\n",
    "For convenience, we can summarize all this information. This will produce an `RDS` file (`res.rds`), a table of strain frequencies (`strain.freq.csv`), and a text file summarizing our tree enrichment statistics (`stats.summary.txt`). However, this step can be slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78521bf4-e8d9-4d18-9dbd-c7dd4ec2011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$mg.tl.strainfinder.script_path\" \"$mg.data.metadata_path\"\n",
    "\n",
    "# first activate previous conda environment \n",
    "conda activate mgxevo\n",
    "\n",
    "# run script\n",
    "Rscript $1/4.summarise.r \\\n",
    "    --multigene_table ./write/ids.multigene.txt \\\n",
    "    --tree_dir ./write/multigene_phylo/ \\\n",
    "    --metadata $2 \\\n",
    "    --uhgg_metadata ./data/uhgg/genomes-all_metadata.tsv \\\n",
    "    --sf_dir ./write/strainfinder \\\n",
    "    --phylo_enrichment_dir ./write/multigene_phylo \\\n",
    "    --output_dir ./write/ \\\n",
    "    --genomes ./write/genomes.use.txt \\\n",
    "    --strainfinder_tips ./write/strainfinder.final_tips.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b80af2-d8b7-4fa5-a6b5-dc3fe68ba56c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T21:29:32.138437Z",
     "iopub.status.busy": "2024-04-08T21:29:32.138030Z",
     "iopub.status.idle": "2024-04-08T21:29:32.146407Z",
     "shell.execute_reply": "2024-04-08T21:29:32.145752Z",
     "shell.execute_reply.started": "2024-04-08T21:29:32.138323Z"
    },
    "tags": []
   },
   "source": [
    "#### _In silico_ strain competition experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e057a98e-cae2-4f31-9b6d-b05e19cdb9b3",
   "metadata": {},
   "source": [
    "To perform an _in silico_ strain competition experiment we can leverage our longitudinal data. To begin, we first re-run StrainFinder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73819830-6d3c-4162-a24d-ca0f29649fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p ./write/strainfinder\n",
    "for genome in (cat ./write/genomes.use.txt); do\n",
    "    python $1/3.run_sf.py \\\n",
    "        --genome $genome \\\n",
    "        --aln ./write/multigene_np/$genome.multigene.aln.pickle \\\n",
    "        --tree ./write/multigene_phylo/$genome.tree \\\n",
    "        --samples ./data/samples.txt \\\n",
    "        --metadata $2 \\\n",
    "        --final_tips ./write/strainfinder.final_tips.txt \\\n",
    "        --output ./write/strainfinder/$genome.sf.long.txt\n",
    "        --use_phylo 0\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ad5b56-c1aa-4333-bf64-a4c1d2e41e51",
   "metadata": {},
   "source": [
    "We can now load Table S1 and select the appropriate time points for our strain competition experiment (see **Methods**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0eff1c-549d-4e80-93e1-e5e7b902e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$mg.tl.strainfinder.script_path\" \"$mg.data.metadata_path\"\n",
    "\n",
    "# first activate previous conda environment \n",
    "conda activate mgxevo\n",
    "\n",
    "# run script\n",
    "Rscript $1/5.compete_strains.r \\\n",
    "    --multigene_table ./write/ids.multigene.txt \\\n",
    "    --bowtie_aln ./abundance/bowtie_abundances.csv \\\n",
    "    --metadata $2 \\\n",
    "    --sf_dir ./write/strainfinder \\\n",
    "    --phylo_enrichment_dir ./write/multigene_phylo \\\n",
    "    --output_dir ./write/ \\\n",
    "    --genomes ./write/genomes.use.txt \\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a77ce9-9325-40e9-8c47-4cdef3fd5b0e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fecal calprotectin predictions\n",
    "\n",
    "The following code runs both our Random Forest and GBM models over a wide range of parameters, saving the combined output in an RDS file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8478000d-8966-4588-bf6c-b11f3e9dcad2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$mg.tl.gene_strain.script_path\" \"$mg.data.metadata_path\"\n",
    "\n",
    "# run RF and GBM models over a wide range of parameters (with n=100 replicates)\n",
    "for a in {0,25,50}; do\n",
    "    for b in {500,1000,2000}; do \n",
    "        for c in {1,2}; do \n",
    "            for n in {1..100}; do \n",
    "                Rscript $1/run_fcp_models.r \\\n",
    "                    --metadata $2 \\\n",
    "                    --panel ./write/ids.multigene.txt \\\n",
    "                    --nr ./write/multigene.nr.txt \\\n",
    "                    --abd ./write/abundance/bowtie_abundances.csv \\\n",
    "                    --freqs ./write/strain.freq.csv \\\n",
    "                    --phylo_enrichment ./write/multigene_phylo \\\n",
    "                    --cut1 0.$a \\\n",
    "                    --cut2 $b \\\n",
    "                    --ibd FALSE \\\n",
    "                    --fopt $c \\\n",
    "                    --coh sdf \\\n",
    "                    --outdir ./write/ \\\n",
    "                    --out res.$a.$b.FALSE.$c.prism.$n.rds; \n",
    "            done;\n",
    "        done;\n",
    "    done;\n",
    "done;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a905bbc2-84d8-4180-970b-b3790a31660d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Gene strain inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c66fd8-f46f-497f-8121-1f028045765b",
   "metadata": {},
   "source": [
    "To perform our gene-strain inference, we first iterate through our phylogenies to identify genomes that have a sufficient number of reference genomes to infer the content of our disease-adapted strains. Next, for each reference genome that integrates into a disease-adapted node, we store the relevant pan-genome presence-absence matrices in an RDS file called `*.mtx.rds`. Finally, we run our enrichment model on each of these matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde1bcd-e73d-44b4-b921-0d37bd96b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$mg.tl.gene_strain.script_path\"\n",
    "\n",
    "# first identify genomes that we can use\n",
    "Rscript $1/1.select_ids.r \\\n",
    "    --uhgg_dir ./data/uhgg/ \\\n",
    "    --info ./write/stats.summary.txt \\\n",
    "    --phylo_dir ./write/multigene_phylo \\\n",
    "    --outdir ./write/\n",
    "\n",
    "# merge pan-genomes into a convenient RDS file\n",
    "tail -n +2 ./write/ids.use.txt | cut -f1 | parallel --progress -j 30 \"Rscript $1/2.build_mtx.r \\\n",
    "    --genome {} \\\n",
    "    --gene_strain_ids ./write/ids.use.txt \\\n",
    "    --uhgg_dir ./data/uhgg/ \\\n",
    "    --phylo_dir ./write/multigene_phylo/ \\\n",
    "    --outdir ./write/\"\n",
    "\n",
    "# run enrichment script\n",
    "tail -n +2 ./write/ids.use.txt | cut -f1 | parallel --progress -j 30 \"Rscript $1/3.enrichment.r \\\n",
    "    --genome {} \\\n",
    "    --gene_strain_ids ./write/ids.use.txt \\\n",
    "    --uhgg_dir ./data/uhgg/ \\\n",
    "    --mtx_dir ./write/ \\\n",
    "    --outdir ./write/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48315cc0-3082-49b5-93c8-d3062ae0cef7",
   "metadata": {},
   "source": [
    "### DIAMOND\n",
    "To validate our gene-strain predictions, we use [DIAMOND](https://github.com/bbuchfink/diamond) to obtain gene abundance estimates, specifically focusing on genes that occur in >100 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460b1878-05ce-4960-87a1-5c68a0143db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# get a list of all FASTQ files\n",
    "all_fastq = glob.glob('../2.map_reads/data/reads/*.trim.fastq.gz')\n",
    "all_fastq = sorted([os.path.basename(x).replace('.trim.fastq.gz', '') for x in all_fastq])\n",
    "\n",
    "with open('data/fastqs.txt', 'w') as f:\n",
    "    f.write('\\n'.join(all_fastq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a397fe5-168f-4d2e-9bd5-4caad7cf493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$mg.tl.gene_strain.script_path\" \n",
    "\n",
    "# run DIAMOND\n",
    "mkdir -p ./write/diamond\n",
    "cat data/fastqs.txt | parallel --progress -j 35 \"python $1/1.run_diamond.py \\\n",
    "    -q ../2.map_reads/data/reads/{}.trim.fastq.gz \\\n",
    "    -o ./write/diamond/{} \\\n",
    "    -d ../1.uhgg_db/data/uhgg/uhgp-90/uhgp-90_hq-diamond-db.dmnd \\\n",
    "    --threads 10\"\n",
    "\n",
    "# parse output \n",
    "mkdir -p ./write/counts\n",
    "cat data/fastqs.txt | parallel --progress -j 360 \"python $1/2.blast2counts.py \\\n",
    "    --blast ./write/diamond/{}.gz \\\n",
    "    --pct 90 \\\n",
    "    --evalue 1e-8 \\\n",
    "    --output ./write/counts/{}\"\n",
    "\n",
    "# get genes present in >100 samples\n",
    "for f in ./write/counts/*.counts.txt\n",
    "do \n",
    "    head -n 1 $f\n",
    "done >> ./write/genes.txt\n",
    "\n",
    "cat ./write/genes.txt | tr '\\t' '\\n' | awk '//{x[$0]++}END{for(k in x){print(k, x[k])}}' > ./write/gene_counts.txt\n",
    "\n",
    "awk '$2 > 100' ./write/gene_counts.txt | cut -d' ' -f1 > ./write/genes.over100.txt\n",
    "\n",
    "# convert counts to RDS files for downstream analyses\n",
    "mkdir -p ./write/diamond_mtx\n",
    "seq 1 50 | parallel --progress -j 50 Rscript $1/3.get_diamond_mtx.r \\\n",
    "    -i {} \\\n",
    "    -n 50 \\\n",
    "    -g ./write/genes.over100.txt \\\n",
    "    --count_dir ./write/counts \\\n",
    "    --out_dir ./write/diamond_mtx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517e62a9-ad9c-447f-bd5d-7f719d6b4307",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-29T13:52:58.731130Z",
     "iopub.status.busy": "2023-10-29T13:52:58.730892Z",
     "iopub.status.idle": "2023-10-29T13:52:58.738594Z",
     "shell.execute_reply": "2023-10-29T13:52:58.737780Z",
     "shell.execute_reply.started": "2023-10-29T13:52:58.731101Z"
    }
   },
   "source": [
    "Finally, to focus on genes associated with our taxa of interest, we can subset our DIAMOND output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8de489-c199-4bd9-948a-98547b85cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$mg.tl.gene_strain.script_path\" \"$mg.data.metadata_path\"\n",
    "\n",
    "tail -n +2 ./write/ids.use.txt | cut -f1 | parallel --progress -j 30 \"Rscript $1/4.get_dmd_counts_mtx.r \\\n",
    "    --genome {} \\\n",
    "    --metadata $2 \\\n",
    "    --gene_strain_ids ./write/ids.use.txt \\\n",
    "    --uhgg_dir ./data/uhgg/ \\\n",
    "    --phylo_dir ./write/multigene_phylo/ \\\n",
    "    --dmd_dir ./write/diamond_mtx/ \\\n",
    "    --outdir ./write/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1be68e4-7c13-41ee-b099-7be921fdb8a7",
   "metadata": {},
   "source": [
    "### Putative _E. lenta_ gene predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e11996-0562-4bc1-ba67-8dcee2191673",
   "metadata": {},
   "source": [
    "To identify gene groups that are co-abundant with _E. lenta_ abundances, we first generate a table of _E. lenta_ abundance; and a list of core _E. lenta_ genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924ecac5-853c-4050-8663-71e8606c2e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$mg.tl.gene_strain.script_path\" \"$mg.data.metadata_path\"\n",
    "\n",
    "Rscript $1/1.get_elenta_ab.r\\\n",
    "    --metadata $2 \\\n",
    "    --panel ./write/ids.multigene.txt \\\n",
    "    --abd ./write/abundance/bowtie_abundances.csv \\\n",
    "    --strain_freq ./write/strain.freq.csv \\\n",
    "    --phylo_enrichment ./write/multigene_phylo \\\n",
    "    --uhgg_dir ./data/uhgg/ \\\n",
    "    --outdir ./write/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4ece9b-22e3-4716-8048-761a0d7d0051",
   "metadata": {},
   "source": [
    "We next correlate our gene abundances from DIAMOND against these _E. lenta_ abundances, and use these to make predictions about which genes _may_ be associated with _E. lenta_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415610f9-6392-43a1-a991-2a4dbf594169",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$mg.tl.gene_strain.script_path\" \"$mg.data.metadata_path\"\n",
    "\n",
    "# 1) first calcualte the row sum for our diamond matrix\n",
    "Rscript $1/2.calc_dmd_rowSum.r\\\n",
    "    --metadata $2 \\\n",
    "    --panel ./write/ids.multigene.txt \\\n",
    "    --abd ./write/abundance/bowtie_abundances.csv \\\n",
    "    --dmd_dir ./write/diamond_mtx/ \\\n",
    "    --outdir ./write/\n",
    "\n",
    "# 2) calculate correlations on chunked matricies\n",
    "seq 1 50 | parallel --progress -j 50 Rscript $1/3.calc_elenta_cor.r \\\n",
    "    --metadata $2 \\\n",
    "    --el_abd ./write/el.ab.tsv \\\n",
    "    --dmd_dir ./write/diamond_mtx/ \\\n",
    "    --gene100 ./write/genes.over100.txt \\\n",
    "    --outdir ./write/ \\\n",
    "    --chunk {}\n",
    "\n",
    "# 3) merge correlation output\n",
    "Rscript $1/4.merge_el_cor.r \\\n",
    "    --outdir ./write/\n",
    "\n",
    "# 4) predict\n",
    "Rscript $1/5.predict_elenta.r \\\n",
    "    --outdir ./write/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62245ee-eab5-4740-a8e3-6372c41fd4fd",
   "metadata": {},
   "source": [
    "Having identified a set of putative _E. lenta_ genes, we can now subset our DIAMOND matrix and run a linear model to identify genes that may possibly associate with health- or disease-associated strains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5211b370-36c7-4035-96fe-d980dbb9809e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$mg.tl.gene_strain.script_path\" \"$mg.data.metadata_path\" \"$mg.tl.uhgg.script_path\"\n",
    "\n",
    "# 6) subset DIAMOND to predicted E. lenta genes\n",
    "Rscript $1/6.subset_diamond.r \\\n",
    "    --meta $2 \\\n",
    "    --gene ./write/el.predicted_genes.txt \\\n",
    "    --dmd_dir ./write/diamond_mtx/ \\\n",
    "    --outdir ./write/ \\\n",
    "    --outfile elenta.rds\n",
    "\n",
    "# 7) run a linear regression model and add KEGG and EggNOG annotations\n",
    "Rscript $1/7.run_elenta_de.r \\\n",
    "    --metadata $2 \\\n",
    "    --abd ./write/el.ab.tsv \\\n",
    "    --uhgp_tools $3 \\\n",
    "    --dmd ./write/elenta.rds \\\n",
    "    --phylo_enrichment ./write/multigene_phylo \\\n",
    "    --uhgg_dir ./data/uhgg/uhgp90/ \\\n",
    "    --tree_dir  ./write/multigene_phylo/ \\\n",
    "    --outdir /write/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
